{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import numpy as np\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "from datetime import timedelta, date\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates=[] #pasirinktų datų sąrašas nuskaitomiems duomenims\n",
    "\n",
    "def daterange(date1, date2):\n",
    "    for n in range(int ((date2 - date1).days)+1):\n",
    "        yield date1 + timedelta(n)\n",
    "\n",
    "start_dt = date(2017, 1, 1) \n",
    "end_dt = date(2017, 12, 31)\n",
    "\n",
    "\n",
    "for dt in daterange(start_dt, end_dt):\n",
    "    dates.append(dt.strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "dates=[d for d in dates if d != '2016-01-21' and d != '2016-04-10' and d != '2017-01-04' \n",
    "       and d != '2017-01-05' and d != '2017-02-22' and d != '2017-02-23' \n",
    "       and d != '2017-02-24' and d != '2017-02-25' and d != '2017-02-26'\n",
    "       and d != '2017-02-27' and d != '2017-02-28' and d != '2017-03-01' \n",
    "       and d != '2017-03-02' and d != '2017-03-03' and d != '2017-03-04'\n",
    "       and d != '2017-03-05' and d != '2017-03-06' and d != '2017-03-07']\n",
    "#2016-01-21 - .doc failas įkeltas\n",
    "#2016-04-10 - cannot reshape array of size 294 into shape (22,14)\n",
    "#2017-01-04-05 - nėra eilutės 'Kiti išvykimai', vietoj jos 2 kartus 'Ekstremaliąsias situacijas'\n",
    "#2017-02-22-03-07 - cannot reshape array of size 330 into shape (22,14), 'nematomas stulpelis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Judita\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:48: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfs1 = [] #Lentelių sąrašas paros duomenų lentelei apie ekstrem. situacijas ir įvykius, gaisrus bei gelbėjimo darbus sukurti\n",
    "#dfs2 = [] Lentelių sąrašas paros gaisrų aprašymų lentelei sukurti\n",
    "\n",
    "for dateurl in dates:\n",
    "    url = 'http://www.vpgt.lt/vpgt/m/m_events_summary/wfiles/e_'+dateurl+'.htm'\n",
    "    result = requests.get(url)\n",
    "    c = result.content\n",
    "    soup = BeautifulSoup(c,'lxml')\n",
    "    table = soup.find('table')\n",
    "    rows = table.find_all('tr')\n",
    "    \n",
    "    data0=[] #duomenų sąrašas\n",
    "    \n",
    "    for tr in rows:\n",
    "        cols = tr.find_all('td')\n",
    "        for td in cols:\n",
    "            text = td.find_all(text=True)\n",
    "            for t in text:\n",
    "                data0.append(t)\n",
    "\n",
    "                \n",
    "    #Paros duomenys apie ekstrem. situacijas ir įvykius, gaisrus bei gelbėjimo darbus\n",
    "    data0 = [w.replace('\\r\\n ', '') for w in data0]\n",
    "    data1 = data0[data0.index('Ekstremaliąsias situacijas'):data0.index('2. Gaisrų aprašymas')]\n",
    "    data1 = [a for a in data1 if a != '\\n' and not('\\xa0 ' in a)]    \n",
    "    if data1[140] == 'd) pagalba ':\n",
    "        data1[140:143] = [''.join(data1[140:143])]\n",
    "    \n",
    "    df01 = pd.DataFrame(np.array(data1).reshape(22,14), columns =[\"Duomenys apie:\", \"2017 nuo metų pr.\", \"2018 nuo metų pr.\", \"Iš viso per parą\", \"Vilniaus apskritis\", \"Kauno apskritis\", \"Klaipėdos apskritis\", \"Šiaulių apskritis\", \"Panevėžio apskritis\", \"Alytaus apskritis\", \"Utenos apskritis\", \"Marijampolės apskritis\", \"Tauragės apskritis\", \"Telšių apskritis\"])\n",
    "    \n",
    "    df01 = df01.drop(df01.columns[1:4], axis=1)\n",
    "    df01 = df01.T.drop([2,6,13], axis=1)\n",
    "    df01 = df01.rename(columns=df01.iloc[0]).drop(['Duomenys apie:']).reset_index()\n",
    "    df01['Data'] = dateurl\n",
    "    #df01['d) kitur'] = '' #2016-04-10\n",
    "    dfs1.append(df01)\n",
    "    \n",
    "    \n",
    "    ############\n",
    "    #Paros gaisrų aprašymų duomenys\n",
    "    #data2 = data0[data0.index('2.\\r\\n  Gaisrų aprašymas'):data0.index('XXXXXXXXXXXXXXXX')]\n",
    "    #df02\n",
    "    #dfs2.append(df02)\n",
    "    ############\n",
    "\n",
    "    \n",
    "# paros duomenų lentelė df1 apie ekstrem. situacijas ir įvykius, gaisrus bei gelbėjimo darbus\n",
    "df1 = pd.concat(dfs1, ignore_index=True)\n",
    "df1['Žuvę ne gaisre'], df1['Traumuoti ne gaisre'] = df1['Žuvę/traumuoti ne gaisre'].str.split('/',1).str\n",
    "df1 = df1.drop(['Žuvę/traumuoti ne gaisre'], axis=1)\n",
    "df1 = df1.rename(index=str, columns={\"index\": \"Apskr\", \"Ekstremaliąsias situacijas\": \"EkstSitu\", \n",
    "                                    \"Ekstremaliuosius įvykius\": \"EkstIvyk\", \"GAISRUS:\": \"GAISRAI\", \n",
    "                                    \"a) Gaisruose žuvusius\": \"Zuve_gaisr\", \"b) traumuotus asmenis\": \"Trau_gaisr\", \n",
    "                                    \"a) transporto avarijose\": \"GD_tr_av\", \"b) vandenyje\": \"GD_vand\", \n",
    "                                    \"c) buityje\": \"GD_buit\", \"d) pagalba spec. tarnyboms\": \"GD_sp_trn\", \n",
    "                                    \"e) chemija ir radiacija\": \"GD_ch_rad\", \"f) kitus\": \"GD_kiti\", \n",
    "                                    \"a) gaisruose\": \"Isg_gaisr\", \"b) buityje, vandenyje\": \"Isg_buit_vand\",\n",
    "                                    \"c) transporto avarijose\": \"Isg_tr_av\", \"d) kitur\": \"Isg_kitur\",\n",
    "                                    \"Evakuoti žmonės\": \"Evak_zm\", \"Melagingi pranešimai\": \"MP\", \"KITI IŠVYKIMAI\": \"KI\",\n",
    "                                     \"Žuvę ne gaisre\": \"Zuve_negsr\", \"Traumuoti ne gaisre\": \"Trau_negsr\" })\n",
    "df1 = df1[['Data','Apskr', 'EkstSitu', 'EkstIvyk', 'GAISRAI',\n",
    "               'GD_tr_av', 'GD_vand', 'GD_buit', 'GD_sp_trn', 'GD_ch_rad', 'GD_kiti',\n",
    "               'MP', 'KI', 'Evak_zm', 'Isg_gaisr', 'Isg_buit_vand', 'Isg_tr_av', 'Isg_kitur',\n",
    "               'Trau_gaisr', 'Trau_negsr', 'Zuve_gaisr', 'Zuve_negsr']]\n",
    "\n",
    "\n",
    "############\n",
    "#Paros gaisrų aprašymų lentelė\n",
    "#df2 = pd.concat(dfs2, ignore_index=True)\n",
    "############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('2017.csv', index=False, header=True, encoding=\"cp1257\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
